# DataPulse Refactoring Walkthrough

项目已按照最新的 `project.md` 设计完成全面重构。

## 主要变更点

### 1. 核心架构升级
- **双数据库并行**：SQLite (`datapulse.db`) 负责管理任务、历史和配置；DuckDB (`analytics.duckdb`) 负责百万级业务数据的高速分析。
- **计算引擎集成**：核心逻辑深度集成 Polars，确保在处理大规模数据时的低内存占用与高吞吐量。

### 2. 全新的 9 大功能模块 (0-8)
利用 Streamlit 的 `st.navigation` 重新组织了界面：
- **0. 工作看板**：支持任务卡片管理与最近访问表的快速导航。
- **1. 概况统计**：系统审计与磁盘占用实时监控。
- **2. 数据资产**：集成 **chardet** 自动识别 CSV 编码，支持一键导入百万级数据。
- **3. 数据查询**：支持 SQL 与 GUI 混合模式，提供计算引擎切换选项（Polars/Pandas）。
- **4. 数据处理**：可视化算子链（去重、填充、删除等），实现低代码数据清洗。
- **5. 可视化引擎**：升级至 **Plotly**，支持交互式图表与一键导出 HTML 报告。
- **6. 历史与快照**：SQL 历史回溯与 Parquet 格式的结果快照管理。
- **7. 系统管理**：语言切换、主题偏好与存储路径配置。
- **8. 全局搜索**：集成 **Command Palette**，支持跨模块搜索及 Action 命令。

### 3. UI/UX 增强
- **侧边栏监控**：底部集成实时 CPU/内存/磁盘状态栏，通过 `st.fragment` 实现 5 秒无感刷新。
- **更专业的样式**：采用更现代的图标与组件布局。

## 验证结果
- [x] **导航验证**：9 个模块均可正常切换，加载流畅。
- [x] **导入性能**：`io_handler.py` 现在能更可靠地识别文件编码。
- [x] **数据流动**：查询结果可在可视化与处理模块间无缝传递（通过 session_state）。

## 待续事项
- 集成 `PyApp` 进行自动化打包。
- 完善数据处理模块的更多高级算子。
