DataPulse——本地数据管理系统

---

## 核心架构

为了实现“百万级处理、低开销、易交付”

* **存储引擎：** **DuckDB**。适合单机本地分析的 OLAP 数据库，处理百万级数据仅需毫秒级，且无需安装服务端，直接内嵌在程序中。同时**SQLite**作为OLTP。
* **计算库：** **Polars**。配合 DuckDB 极速处理大规模数据的转换。增加**Pandas**作为协同/备选方案。
* **UI 框架：** **Streamlit**。
* **开发辅助：** uv，pydantic，pydoc-markdown，mkdocs，schemathesis


---

## 功能模块说明书


### 0. 工作看板 (Work dashboard)

**模块说明：** 规划工作和快速跳转

**页面布局：** 左右布局，中间分割线

**包含功能：**
* **任务卡片：** 支持创建“数据处理流水线”任务，例如“处理 2月 销售报表”，并关联相应的 SQL 脚本。
* **最近访问：** 自动罗列最近查询过的表或最近导出的结果，可点击跳转。


### 1. 概况统计 (Summary statistics)

**模块说明：** 查看系统的情况统计，如当前存了多少表，多少条SQL操作记录，多少个临时快照，这些表/快照分别总计花了多少存储空间。

**页面布局：** 多个数据卡片展示信息。

**包含功能：**
* **数据库审计：** 统计导入的表格、暂存的记录、快照，系统所在磁盘的情况。
* **活跃度画像：** 通过热力图展示用户对哪些内容操作最频繁。


### 2. 数据资产 (Data Assets)

**模块说明：** 数据导入和表查看。

**页面布局：** 类数据库管理软件布局

**包含功能：**
* **数据导入：** 文件选择器，多种导入设置（跳过行，选取列等），自动识别 CSV/Excel 的编码、分隔符和字段类型（尤其是日期格式的自动解析）。
* **表查看：** 分页查看元数据、行内容。


### 3. 数据查询 (Data Query)

**模块说明：** 数据查询和结果暂存。

**页面布局：** 类数据库管理软件布局

**包含功能：**
* **混合管理：** 支持常规的 **GUI 交互** 与 **SQL 模式** 并行，可选由polars或pandas驱动。
* **分页加载：** 即使是百万级数据，前端也只按配置渲染当前可见的行数，确保界面不卡顿。
* **结果暂存：** 可将查询的SQL或得到的数据暂存，方便后续取用。


### 4. 数据处理 (Data Process)

**模块说明：** 数据后处理，将常见的清洗任务（去重、空值填充、类型转换、列拆分）封装成标准的 Python 算子。

**页面布局：** 类似流程图

**包含功能：**
* **工作流：** 通过 st.multiselect 组合算子链，可视化配置。
* **可配参数：** 提供多种清洗工具，提供多样选项或参数，快速清洗。


### 5. 可视化引擎 (Insights Engine)

**模块说明：** 绘图。

**页面布局：** 

**包含功能：**
* **快速绘制：** 根据选择的图表类型绘制并提供参数调节，快速调整。
* **交互式看板：** 绘图不仅仅是静态图片，支持缩放、悬停查看数值。
* **图表联动：** 使用 streamlit-plotly-events 等组件，可以实现“点击图表上的条形，数据表格自动过滤”的交互体验。
* **导出能力：** 支持将图表导出为高质量的网页 (HTML) 或矢量图 (SVG)，方便放入报告或PPT。


### 6. 历史与快照 (History & Snapshots)

**模块说明：** 每个载体都能暂存，SQL、查询的结果、数据处理的结果、绘制的图片。

**页面布局：** 

**包含功能：**
* **查询回溯：** 临时记录当次系统启动后每一条执行过的 SQL 和数据结果，持久化记录手动暂存的 SQL 和数据结果，支持一键复用。
* **结果快照：** 对于复杂的耗时查询，支持将结果存为 **.parquet** 临时文件。这样下次查看时无需重新计算，直接读取。
* **版本备注：** 可以给某次查询结果打标签（如：“2024年终最终核算版”）。


### 7. 系统管理 (System Management)

**模块说明：** 配置系统的功能。

**页面布局：** 

**包含功能：**
* **基础配置：** 主题，背景等。
* **高级配置：** 多语言。
* **存储配置：** 不同的存储路径。


### 8. 全局搜索 (Command Palette)

* **技术路径：** 在 Streamlit 顶部利用 streamlit-searchbox 或自定义组件实现。

* **搜索索引：** 程序启动时，将 analytics.duckdb 中的表名、字段名，以及 datapulse.db 中的 SQL 历史和任务名索引到内存。

* **Action 命令：** 支持输入 > export 直接跳转导出页面，输入 t: table_name 直接跳转表查看，模拟 VS Code 的 Ctrl+P 体验。


---

## 增强设计 (UX & Performance) ——可选进阶

| 模块       | 深度优化建议                | 实现细节                                                                               |
|----------|-----------------------|------------------------------------------------------------------------------------|
| **数据导入** | **编码识别**              | 导入模块建议集成 chardet 或 charset-normalizer，解决 Excel/CSV 乱码的痛点。                          |
| **数据导入** | **进度反馈**              | 导入百万级数据时，建议使用 st.progress 结合 DuckDB 的 Appender 机制，提供实时的导入百分比。                      |
| **内存管理** | **零拷贝读取 (Zero-copy)** | 利用 **Polars 与 DuckDB 的深度集成**。使用 `duckdb.query().pl()`，让数据在内存中直接传递，避免在百万级数据下发生 OOM。 |
| **错误处理** | **SQL 语法沙箱**          | 在用户点击执行前，先用 `EXPLAIN` 命令预检 SQL 语法，并在报错时给出友好的提示（而非原始的 Traceback）。                   |
| **操作回滚** | **事务机制**              | 增加“操作撤销”或“事务回滚”机制，防止 SQL 误删数据。                                                     |

SQL 注入防御： 即使是本地工具，也应在 core/database.py 中处理好参数化查询。

幂等性设计： 确保同一份数据重复导入时，系统能智能识别（通过 Hash 或元数据对照），而不是简单报错或重复。

---

## 工程目录结构

```text
dataPulse/
├── .streamlit/                # Streamlit 界面配置 (主题、页面设置)
│   └── config.toml
├── .venv/                     # uv管理的本地环境
├── assets/                    # 静态资源 (Logo, 样式表, 示例数据)
│   ├── css/                   # 自定义样式，让 Streamlit 更像原生软件
│   └── samples/               # 内置的 10 万行示例数据 (csv/parquet)
├── changes/                   # AI编程修改记录
│   ├── 20260205-1/            # 某次修改归档的文件夹
│   └── ...
├── data/                      # 本地持久化数据 (Git 忽略)
│   ├── snapshots/             # 暂存和快照
│   ├── datapulse.db           # SQLite: 存储 配置, 日志
│   └── analytics.duckdb       # DuckDB: 存储用户导入的百万级业务数据
├── docs/                      # MkDocs 原型：存储系统说明文档
│   ├── api/                   # 生成的api文档
│   └── index.md               # 生成的文档首页
├── scripts/                   # 构建与交付脚本
│   └── build.py               # 自动化打包脚本
├── src/                       # 核心源代码
│   ├── __init__.py
│   ├── main.py                # 程序入口 (Streamlit Entry Point)
│   │
│   ├── core/                  # 底层驱动层
│   │   ├── database.py        # 数据库连接池 (DuckDB & SQLite 交互逻辑)
│   │   ├── engine.py          # Polars/Pandas 计算引擎封装
│   │   └── config.py          # 全局配置管理
│   │
│   ├── pages/                 # navigation页面
│   │
│   ├── modules/               # 功能模块层
│   │
│   ├── ui/                    # UI 组件库
│   │   ├── components.py      # 自定义封装的 Streamlit 组件
│   │   └── status_bar.py      # 底部状态栏 (系统性能监控)
│   │
│   └── utils/                 # 通用工具类
│       ├── logger.py          # 日志记录器
│       ├── io_handler.py      # 文件编码自动识别、断点续传逻辑
│       └── metrics.py         # 硬件指标获取 (psutil 封装)
│
├── tests/                     # 单元测试 (百万级数据压力测试)
├── pyproject.toml             # uv/poetry 项目配置文件
└── README.md                  # 项目文档

```

---

## 目录设计要点说明

### 1. 双数据库分离存储 (Core Layer)

* 将 `datapulse.db` (SQLite) 和 `analytics.duckdb` (DuckDB) 分开。
* **理由：** SQLite 处理高频的增删改（Todo、日志）更稳定；DuckDB 专注于只读或大批量写入的分析任务。

### 2. 模块化视图 (Modules Layer)

* 不要把所有逻辑写在 `main.py`。建议使用 Streamlit 的 `st.navigation` (v1.31+) 功能，将每个功能模块解耦。
* 每个模块内部只关心业务逻辑，数据的读取通过 `core/database.py` 统一获取，实现**逻辑与展示分离**。

### 3. 快照管理 (History & Snapshots)

* 在 `data/` 下 `snapshots/` 子目录，专门存放用户点击“结果暂存”后生成的 `.parquet` 文件。
* Parquet 格式与 DuckDB/Polars 完美兼容，读取速度极快。

### 4. 交付与性能监控 (UI & Utils)

* `utils/metrics.py`：使用 `psutil` 库实时监控本地 CPU 和内存。
* 在 `ui/status_bar.py` 中调用这些指标，利用 Streamlit 的 `st.sidebar` 底部实现动态刷新，让用户对“电脑跑不动了”有直观感受。

### 5. 易于交付 (Packaging)

* 通过 uv + `pyproject.toml` 管理依赖。
* 交付时，提供可直接运行的文件。 封装工具： 使用 PyApp 或 Briefcase，而非传统的 PyInstaller。

PyApp： 可以将 Python 环境和 uv 管理的依赖打包成一个极小的引导程序，运行时自动设置环境。
内置运行库： 考虑分发一个集成了 Python 环境的压缩包（Portable Python）。
结构： DataPulse.exe (启动器) + _internal/ (Python 运行环境 + 依赖库)。
数据库初始化： 在 main.py 中加入 Migration (迁移) 逻辑。如果发现 data/ 下没有数据库，自动执行 DDL 初始化表结构并存入示例数据。


---
