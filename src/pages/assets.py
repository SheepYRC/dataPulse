import streamlit as st
from src.core.database import db_manager
import pandas as pd

def show():
    st.title("ğŸ“Š æ•°æ®èµ„äº§çœ‹æ¿ (Data Assets)")
    
    duck_conn = db_manager.get_duckdb()
    
    # 1. Data Import Section
    with st.expander("ğŸ“¥ å¯¼å…¥æ–°æ•°æ®", expanded=False):
        uploaded_file = st.file_uploader("é€‰æ‹© CSV, Excel æˆ– Parquet æ–‡ä»¶", type=["csv", "xlsx", "parquet"])
        #print("uploaded_file",uploaded_file)
        table_name = st.text_input("ç›®æ ‡è¡¨å", value="imported_table")
        
        # Validation logic
        import re
        valid_name_regex = r'^[a-zA-Z0-9_\-]+$' # Allow alphanumeric, dash, and underscore
        
        if uploaded_file and st.button("ğŸš€ å¼€å§‹å¯¼å…¥"):
            if not table_name:
                st.error("âŒ é”™è¯¯ï¼šè¡¨åä¸èƒ½ä¸ºç©ºã€‚")
            elif not re.match(valid_name_regex, table_name):
                st.error(f"âŒ é”™è¯¯ï¼šè¡¨å '{table_name}' åŒ…å«éæ³•å­—ç¬¦ã€‚å»ºè®®ä»…ä½¿ç”¨å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿æˆ–è¿å­—ç¬¦ã€‚")
            else:
                import tempfile
                import os
                from src.utils.io_handler import import_to_duckdb
                
                with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmp:
                    tmp.write(uploaded_file.getvalue())
                    tmp_path = tmp.name
                
                with st.spinner("æ­£åœ¨å¯¼å…¥ç™¾ä¸‡çº§å¼•æ“..."):
                    success = import_to_duckdb(tmp_path, table_name, duck_conn)
                    os.unlink(tmp_path)
                if success:
                    st.success(f"æˆåŠŸå¯¼å…¥: {table_name}")
                    st.rerun()
                else:
                    st.error("å¯¼å…¥å¤±è´¥ï¼Œè¯¦è§ç³»ç»Ÿæ—¥å¿—ã€‚")

    st.divider()

    # 2. Overview Metrics
    st.subheader("ğŸ“¦ å­˜å‚¨æ¦‚è§ˆ")
    try:
        storage_info = duck_conn.execute("PRAGMA database_size").df()
        db_size = storage_info['database_size'].iloc[0]
        st.metric("åˆ†ææ•°æ®åº“ä½“ç§¯", db_size)
    except:
        st.info("æ— æ³•è·å–è¯¦ç»†å­˜å‚¨æŒ‡æ ‡ï¼Œæ•°æ®åº“å¯èƒ½ä¸ºç©ºã€‚")

    st.divider()

    # 3. Table List & Schema
    st.subheader("ğŸ“‚ æ•°æ®è¡¨æ¸…å•")
    tables = duck_conn.execute("SHOW TABLES").df()
    
    if tables.empty:
        st.warning("å½“å‰æ²¡æœ‰å·²å¯¼å…¥çš„æ•°æ®è¡¨ã€‚")
    else:
        selected_table = st.selectbox("é€‰æ‹©è¡¨ä»¥æŸ¥çœ‹è¯¦æƒ…", tables['name'].tolist())
        
        if selected_table:
            # Metadata
            quoted_table = f'"{selected_table}"'
            schema = duck_conn.execute(f"DESCRIBE {quoted_table}").df()
            row_count = duck_conn.execute(f"SELECT COUNT(*) FROM {quoted_table}").fetchone()[0]
            
            col1, col2 = st.columns(2)
            col1.write(f"**è¡Œæ•°:** {row_count}")
            col2.write(f"**å­—æ®µæ•°:** {len(schema)}")
            
            st.write("**å­—æ®µå®šä¹‰:**")
            st.dataframe(schema, width='content')
            
            # Health Check (Simple version)
            if st.button(f"ğŸ” è¿è¡Œ {selected_table} å¥åº·è¯„ä¼°"):
                with st.spinner("æ­£åœ¨æ‰«ææ•°æ®é‡ä¸ç©ºå€¼..."):
                    # Scan for nulls in each column
                    null_counts = {}
                    for col in schema['column_name']:
                        quoted_table = f'"{selected_table}"'
                        c = duck_conn.execute(f"SELECT COUNT(*) FROM {quoted_table} WHERE {col} IS NULL").fetchone()[0]
                        null_counts[col] = c
                    
                    st.write("**ç©ºå€¼å®¡è®¡:**")
                    st.bar_chart(pd.Series(null_counts))
